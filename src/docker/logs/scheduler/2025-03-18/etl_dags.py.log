[2025-03-18T13:07:38.804+0000] {processor.py:157} INFO - Started process (PID=35) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:07:38.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:07:38.806+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:07:38.806+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:07:38.822+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:07:38.819+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 4, in <module>
    from scripts.extract import extract_data
ModuleNotFoundError: No module named 'scripts'
[2025-03-18T13:07:38.823+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:07:38.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.033 seconds
[2025-03-18T13:08:09.001+0000] {processor.py:157} INFO - Started process (PID=37) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:08:09.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:08:09.003+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:08:09.003+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:08:09.015+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:08:09.013+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 4, in <module>
    from scripts.extract import extract_data
ModuleNotFoundError: No module named 'scripts'
[2025-03-18T13:08:09.016+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:08:09.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.035 seconds
[2025-03-18T13:08:39.217+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:08:39.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:08:39.219+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:08:39.218+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:08:39.230+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:08:39.228+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 4, in <module>
    from scripts.extract import extract_data
ModuleNotFoundError: No module named 'scripts'
[2025-03-18T13:08:39.231+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:08:39.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.033 seconds
[2025-03-18T13:13:18.526+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:13:18.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:13:18.528+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:13:18.528+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:13:19.595+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:13:19.590+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:13:19.596+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:13:19.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.081 seconds
[2025-03-18T13:13:49.846+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:13:49.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:13:49.848+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:13:49.848+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:13:50.194+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:13:50.190+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:13:50.195+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:13:50.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.362 seconds
[2025-03-18T13:14:20.417+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:14:20.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:14:20.419+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:14:20.419+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:14:20.919+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:14:20.914+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:14:20.920+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:14:20.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.515 seconds
[2025-03-18T13:14:51.090+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:14:51.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:14:51.091+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:14:51.091+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:14:51.407+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:14:51.401+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:14:51.409+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:14:51.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.334 seconds
[2025-03-18T13:15:21.592+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:15:21.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:15:21.594+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:15:21.594+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:15:21.965+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:15:21.960+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:15:21.966+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:15:21.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.388 seconds
[2025-03-18T13:15:52.181+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:15:52.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:15:52.182+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:15:52.182+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:15:52.487+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:15:52.483+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:15:52.488+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:15:52.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.330 seconds
[2025-03-18T13:16:22.667+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:16:22.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:16:22.669+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:16:22.669+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:16:23.075+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:16:23.066+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:16:23.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:16:23.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.425 seconds
[2025-03-18T13:16:53.266+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:16:53.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:16:53.268+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:16:53.267+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:16:53.621+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:16:53.616+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:16:53.622+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:16:53.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.370 seconds
[2025-03-18T13:17:23.824+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:17:23.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:17:23.826+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:17:23.825+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:17:24.138+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:17:24.133+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:17:24.139+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:17:24.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.329 seconds
[2025-03-18T13:17:54.372+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:17:54.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:17:54.375+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:17:54.375+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:17:55.036+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:17:55.031+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:17:55.051+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:17:55.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.700 seconds
[2025-03-18T13:18:25.267+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:18:25.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:18:25.269+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:18:25.269+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:18:25.593+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:18:25.589+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:18:25.594+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:18:25.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.343 seconds
[2025-03-18T13:18:55.795+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:18:55.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:18:55.797+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:18:55.797+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:18:56.341+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:18:56.335+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:18:56.342+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:18:56.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.562 seconds
[2025-03-18T13:19:26.545+0000] {processor.py:157} INFO - Started process (PID=106) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:19:26.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:19:26.546+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:19:26.546+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:19:26.839+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:19:26.835+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:19:26.840+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:19:26.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.309 seconds
[2025-03-18T13:19:57.113+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:19:57.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:19:57.125+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:19:57.124+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:19:57.602+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:19:57.591+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:19:57.604+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:19:57.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.505 seconds
[2025-03-18T13:23:18.243+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:23:18.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:23:18.245+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:23:18.245+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:23:19.149+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:23:19.143+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:23:19.150+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:23:19.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.920 seconds
[2025-03-18T13:23:49.507+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:23:49.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:23:49.510+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:23:49.510+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:23:49.882+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:23:49.877+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:23:49.883+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:23:49.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.389 seconds
[2025-03-18T13:24:20.070+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:24:20.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:24:20.072+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:24:20.071+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:24:20.587+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:24:20.580+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:24:20.589+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:24:20.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.533 seconds
[2025-03-18T13:24:50.793+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:24:50.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:24:50.795+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:24:50.795+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:24:51.156+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:24:51.151+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:24:51.157+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:24:51.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.382 seconds
[2025-03-18T13:25:21.358+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:25:21.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:25:21.361+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:25:21.360+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:25:21.697+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:25:21.690+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:25:21.699+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:25:21.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.354 seconds
[2025-03-18T13:25:51.870+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:25:51.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:25:51.872+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:25:51.872+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:25:52.193+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:25:52.188+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:25:52.194+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:25:52.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.339 seconds
[2025-03-18T13:26:22.372+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:26:22.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:26:22.374+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:26:22.374+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:26:22.721+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:26:22.710+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:26:22.722+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:26:22.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.364 seconds
[2025-03-18T13:26:52.902+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:26:52.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:26:52.904+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:26:52.904+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:26:53.226+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:26:53.221+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:26:53.227+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:26:53.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.339 seconds
[2025-03-18T13:27:23.423+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:27:23.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:27:23.425+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:27:23.425+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:27:23.749+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:27:23.737+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:27:23.752+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:27:23.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.348 seconds
[2025-03-18T13:27:54.048+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:27:54.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:27:54.049+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:27:54.049+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:27:54.395+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:27:54.391+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:27:54.397+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:27:54.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.364 seconds
[2025-03-18T13:28:24.568+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:28:24.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:28:24.569+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:28:24.569+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:28:24.906+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:28:24.902+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:28:24.907+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:28:24.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.354 seconds
[2025-03-18T13:28:55.084+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:28:55.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:28:55.086+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:28:55.086+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:28:55.415+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:28:55.410+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:28:55.416+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:28:55.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.348 seconds
[2025-03-18T13:29:25.588+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:29:25.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:29:25.590+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:29:25.590+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:29:25.920+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:29:25.915+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:29:25.921+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:29:25.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.347 seconds
[2025-03-18T13:29:56.093+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:29:56.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:29:56.095+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:29:56.095+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:29:56.428+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:29:56.423+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:29:56.428+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:29:56.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.351 seconds
[2025-03-18T13:30:26.604+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:30:26.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:30:26.605+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:30:26.605+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:30:26.946+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:30:26.942+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:30:26.948+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:30:26.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.359 seconds
[2025-03-18T13:30:57.180+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:30:57.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:30:57.217+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:30:57.217+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:30:57.583+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:30:57.578+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:30:57.584+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:30:57.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.418 seconds
[2025-03-18T13:31:27.785+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:31:27.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:31:27.787+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:31:27.787+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:31:28.150+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:31:28.146+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:31:28.151+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:31:28.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.381 seconds
[2025-03-18T13:31:58.345+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:31:58.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:31:58.347+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:31:58.347+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:31:58.675+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:31:58.669+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:31:58.677+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:31:58.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.346 seconds
[2025-03-18T13:32:28.850+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:32:28.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:32:28.852+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:32:28.851+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:32:29.184+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:32:29.177+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:32:29.185+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:32:29.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.350 seconds
[2025-03-18T13:32:59.346+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:32:59.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:32:59.349+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:32:59.349+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:32:59.677+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:32:59.672+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:32:59.678+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:32:59.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.347 seconds
[2025-03-18T13:33:29.985+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:33:29.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:33:29.986+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:33:29.986+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:33:30.313+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:33:30.309+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:33:30.314+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:33:30.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.345 seconds
[2025-03-18T13:34:15.039+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:34:15.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:34:15.041+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:34:15.040+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:34:15.932+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:34:15.928+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:34:15.933+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:34:15.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.909 seconds
[2025-03-18T13:34:46.136+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:34:46.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:34:46.138+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:34:46.138+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:34:46.488+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:34:46.483+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:34:46.490+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:34:46.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.371 seconds
[2025-03-18T13:35:16.673+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:35:16.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:35:16.675+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:35:16.675+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:35:17.224+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:35:17.218+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:35:17.225+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:35:17.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.566 seconds
[2025-03-18T13:35:47.441+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:35:47.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:35:47.442+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:35:47.442+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:35:47.830+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:35:47.825+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:35:47.831+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:35:47.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.406 seconds
[2025-03-18T13:36:18.057+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:36:18.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:36:18.060+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:36:18.060+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:36:18.451+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:36:18.446+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:36:18.452+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:36:18.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.411 seconds
[2025-03-18T13:36:55.404+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:36:55.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:36:55.405+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:36:55.405+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:36:55.615+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:36:55.611+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:36:55.617+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:36:55.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.227 seconds
[2025-03-18T13:37:07.217+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:37:07.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:37:07.218+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:37:07.218+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:37:07.424+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:37:07.420+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:37:07.425+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:37:07.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.223 seconds
[2025-03-18T13:37:37.616+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:37:37.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:37:37.617+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:37:37.617+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:37:37.874+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:37:37.865+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:37:37.875+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:37:37.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.277 seconds
[2025-03-18T13:38:08.068+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:38:08.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:38:08.070+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:38:08.070+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:38:08.476+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:38:08.468+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:38:08.478+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:38:08.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.426 seconds
[2025-03-18T13:38:38.669+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:38:38.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:38:38.672+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:38:38.671+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:38:38.921+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:38:38.903+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:38:38.922+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:38:38.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.271 seconds
[2025-03-18T13:39:09.122+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:39:09.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:39:09.123+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:39:09.123+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:39:09.339+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:39:09.334+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:39:09.340+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:39:09.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.234 seconds
[2025-03-18T13:39:39.508+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:39:39.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:39:39.509+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:39:39.509+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:39:39.725+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:39:39.720+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:39:39.727+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:39:39.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.236 seconds
[2025-03-18T13:40:09.928+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:40:09.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:40:09.930+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:40:09.930+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:40:10.135+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:40:10.130+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:40:10.136+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:40:10.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.223 seconds
[2025-03-18T13:40:40.302+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:40:40.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:40:40.303+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:40:40.303+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:40:40.514+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:40:40.509+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:40:40.515+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:40:40.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.229 seconds
[2025-03-18T13:41:10.702+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:41:10.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:41:10.704+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:41:10.704+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:41:10.912+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:41:10.906+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:41:10.913+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:41:10.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.228 seconds
[2025-03-18T13:41:41.088+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:41:41.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:41:41.089+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:41:41.089+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:41:41.298+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:41:41.293+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:41:41.299+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:41:41.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.227 seconds
[2025-03-18T13:42:11.388+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:42:11.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:42:11.390+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:42:11.389+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:42:11.631+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:42:11.623+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:42:11.632+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:42:11.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.261 seconds
[2025-03-18T13:42:41.802+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:42:41.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:42:41.804+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:42:41.803+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:42:42.032+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:42:42.026+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:42:42.033+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:42:42.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.247 seconds
[2025-03-18T13:43:12.205+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:43:12.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:43:12.207+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:43:12.207+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:43:12.513+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:43:12.506+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:43:12.514+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:43:12.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.327 seconds
[2025-03-18T13:43:42.753+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:43:42.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:43:42.755+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:43:42.754+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:43:43.057+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:43:43.052+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:43:43.059+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:43:43.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.324 seconds
[2025-03-18T13:44:13.325+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:44:13.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:44:13.327+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:44:13.327+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:44:13.545+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:44:13.540+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:44:13.546+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:44:13.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.237 seconds
[2025-03-18T13:44:43.743+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:44:43.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:44:43.745+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:44:43.745+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:44:44.005+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:44:43.996+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:44:44.007+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:44:44.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.281 seconds
[2025-03-18T13:45:14.192+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:45:14.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:45:14.194+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:45:14.194+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:45:14.441+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:45:14.427+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:45:14.444+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:45:14.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.275 seconds
[2025-03-18T13:45:44.641+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:45:44.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:45:44.642+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:45:44.642+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:45:44.858+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:45:44.852+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:45:44.859+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:45:44.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.237 seconds
[2025-03-18T13:46:15.136+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:46:15.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:46:15.137+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:46:15.137+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:46:15.352+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:46:15.347+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:46:15.354+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:46:15.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.234 seconds
[2025-03-18T13:46:45.549+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:46:45.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:46:45.550+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:46:45.550+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:46:45.805+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:46:45.801+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:46:45.806+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:46:45.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.274 seconds
[2025-03-18T13:47:16.004+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:47:16.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:47:16.006+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:47:16.006+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:47:16.225+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:47:16.220+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:47:16.226+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:47:16.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.239 seconds
[2025-03-18T13:47:46.483+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:47:46.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:47:46.484+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:47:46.484+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:47:46.742+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:47:46.700+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:47:46.743+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:47:46.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.275 seconds
[2025-03-18T13:48:16.913+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:48:16.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:48:16.915+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:48:16.915+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:48:17.115+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:48:17.110+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:48:17.116+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:48:17.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.219 seconds
[2025-03-18T13:48:47.297+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:48:47.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:48:47.299+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:48:47.299+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:48:47.552+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:48:47.541+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:48:47.553+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:48:47.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.274 seconds
[2025-03-18T13:49:17.832+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:49:17.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:49:17.834+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:49:17.833+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:49:18.062+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:49:18.057+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:49:18.063+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:49:18.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.249 seconds
[2025-03-18T13:49:48.290+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:49:48.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:49:48.292+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:49:48.292+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:49:48.517+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:49:48.513+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:49:48.519+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:49:48.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.244 seconds
[2025-03-18T13:50:18.583+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:50:18.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:50:18.585+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:50:18.585+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:50:18.806+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:50:18.800+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:50:18.807+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:50:18.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.240 seconds
[2025-03-18T13:50:48.978+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:50:48.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:50:48.981+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:50:48.981+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:50:49.215+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:50:49.209+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:50:49.216+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:50:49.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.254 seconds
[2025-03-18T13:51:19.432+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:51:19.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:51:19.434+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:51:19.434+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:51:19.633+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:51:19.629+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:51:19.634+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:51:19.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.217 seconds
[2025-03-18T13:51:49.854+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:51:49.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:51:49.855+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:51:49.855+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:51:50.069+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:51:50.063+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:51:50.070+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:51:50.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.232 seconds
[2025-03-18T13:52:20.125+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:52:20.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:52:20.126+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:52:20.126+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:52:20.340+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:52:20.335+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:52:20.341+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:52:20.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.231 seconds
[2025-03-18T13:52:50.416+0000] {processor.py:157} INFO - Started process (PID=98) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:52:50.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:52:50.418+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:52:50.418+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:52:50.619+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:52:50.614+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:52:50.620+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:52:50.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.218 seconds
[2025-03-18T13:53:20.723+0000] {processor.py:157} INFO - Started process (PID=100) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:53:20.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:53:20.724+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:53:20.724+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:53:20.934+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:53:20.929+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:53:20.935+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:53:20.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.230 seconds
[2025-03-18T13:53:50.993+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:53:50.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:53:50.994+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:53:50.994+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:53:51.324+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:53:51.320+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:53:51.325+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:53:51.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.347 seconds
[2025-03-18T13:54:21.510+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:54:21.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:54:21.511+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:54:21.511+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:54:21.730+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:54:21.724+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:54:21.731+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:54:21.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.239 seconds
[2025-03-18T13:54:51.973+0000] {processor.py:157} INFO - Started process (PID=106) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:54:51.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:54:51.974+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:54:51.974+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:54:52.198+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:54:52.193+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:54:52.199+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:54:52.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.244 seconds
[2025-03-18T13:55:22.428+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:55:22.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:55:22.430+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:55:22.429+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:55:22.658+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:55:22.649+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:55:22.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:55:22.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.248 seconds
[2025-03-18T13:55:52.871+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:55:52.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:55:52.873+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:55:52.872+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:55:53.079+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:55:53.074+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:55:53.080+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:55:53.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.224 seconds
[2025-03-18T13:56:23.289+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:56:23.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:56:23.291+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:56:23.291+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:56:23.514+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:56:23.507+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:56:23.516+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:56:23.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.244 seconds
[2025-03-18T13:56:53.737+0000] {processor.py:157} INFO - Started process (PID=114) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T13:56:53.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T13:56:53.739+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:56:53.739+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:56:53.964+0000] {logging_mixin.py:154} INFO - [2025-03-18T13:56:53.956+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T13:56:53.966+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T13:56:53.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.244 seconds
[2025-03-18T14:12:52.355+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:12:52.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:12:52.357+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:12:52.357+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:12:53.426+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:12:53.422+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:12:53.427+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:12:53.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.085 seconds
[2025-03-18T14:13:23.594+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:13:23.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:13:23.595+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:13:23.595+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:13:23.927+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:13:23.922+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:13:23.929+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:13:23.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.355 seconds
[2025-03-18T14:13:54.101+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:13:54.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:13:54.102+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:13:54.102+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:13:54.657+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:13:54.651+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:13:54.658+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:13:54.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.574 seconds
[2025-03-18T14:14:24.864+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:14:24.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:14:24.866+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:14:24.866+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:14:25.173+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:14:25.169+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:14:25.174+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:14:25.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.323 seconds
[2025-03-18T14:14:55.343+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:14:55.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:14:55.345+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:14:55.345+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:14:55.676+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:14:55.671+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:14:55.677+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:14:55.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.348 seconds
[2025-03-18T14:15:25.858+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:15:25.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:15:25.860+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:15:25.860+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:15:26.195+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:15:26.189+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:15:26.196+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:15:26.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.352 seconds
[2025-03-18T14:15:56.483+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:15:56.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:15:56.484+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:15:56.484+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:15:56.802+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:15:56.795+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:15:56.804+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:15:56.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.338 seconds
[2025-03-18T14:16:27.002+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:16:27.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:16:27.004+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:16:27.003+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:16:27.357+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:16:27.349+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:16:27.358+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:16:27.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.371 seconds
[2025-03-18T14:16:57.616+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:16:57.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:16:57.618+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:16:57.618+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:16:58.013+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:16:57.962+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:16:58.015+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:16:58.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.416 seconds
[2025-03-18T14:17:28.246+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:17:28.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:17:28.248+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:17:28.248+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:17:28.622+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:17:28.617+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:17:28.623+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:17:28.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.389 seconds
[2025-03-18T14:17:58.815+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:17:58.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:17:58.816+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:17:58.816+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:17:59.128+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:17:59.122+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:17:59.130+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:17:59.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.329 seconds
[2025-03-18T14:18:29.348+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:18:29.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:18:29.350+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:18:29.350+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:18:29.744+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:18:29.735+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:18:29.746+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:18:29.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.414 seconds
[2025-03-18T14:18:59.925+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:18:59.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:18:59.927+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:18:59.927+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:19:00.260+0000] {logging_mixin.py:154} INFO - None
[2025-03-18T14:19:00.266+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:19:00.261+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 15, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:19:00.267+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:19:00.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.355 seconds
[2025-03-18T14:19:30.529+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:19:30.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:19:30.530+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:19:30.530+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:19:30.911+0000] {logging_mixin.py:154} INFO - None
[2025-03-18T14:19:30.917+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:19:30.911+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 15, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:19:30.919+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:19:30.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.408 seconds
[2025-03-18T14:20:01.155+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:20:01.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:20:01.157+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:20:01.156+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:20:01.502+0000] {logging_mixin.py:154} INFO - None
[2025-03-18T14:20:01.510+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:20:01.502+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 15, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:20:01.511+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:20:01.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.372 seconds
[2025-03-18T14:20:31.747+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:20:31.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:20:31.749+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:20:31.749+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:20:32.084+0000] {logging_mixin.py:154} INFO - None
[2025-03-18T14:20:32.089+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:20:32.085+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 15, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:20:32.089+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:20:32.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.357 seconds
[2025-03-18T14:21:02.328+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:21:02.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:21:02.330+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:21:02.330+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:21:02.677+0000] {logging_mixin.py:154} INFO - None
[2025-03-18T14:21:02.682+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:21:02.678+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 15, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:21:02.683+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:21:02.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.369 seconds
[2025-03-18T14:21:32.867+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:21:32.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:21:32.869+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:21:32.869+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:21:33.280+0000] {logging_mixin.py:154} INFO - None
[2025-03-18T14:21:33.287+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:21:33.281+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 15, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:21:33.289+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:21:33.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.440 seconds
[2025-03-18T14:22:03.501+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:22:03.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:22:03.503+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:22:03.502+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:22:03.813+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:22:03.808+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:22:03.814+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:22:03.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.328 seconds
[2025-03-18T14:22:34.035+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:22:34.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:22:34.037+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:22:34.037+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:22:34.383+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:22:34.365+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:22:34.386+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:22:34.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.366 seconds
[2025-03-18T14:23:04.657+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:23:04.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:23:04.659+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:23:04.658+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:23:05.023+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:23:05.017+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:23:05.024+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:23:05.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.383 seconds
[2025-03-18T14:23:35.207+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:23:35.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:23:35.209+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:23:35.209+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:23:35.526+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:23:35.521+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:23:35.527+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:23:35.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.332 seconds
[2025-03-18T14:24:05.699+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:24:05.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:24:05.701+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:24:05.700+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:24:06.010+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:24:06.005+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:24:06.011+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:24:06.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.326 seconds
[2025-03-18T14:35:28.251+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:35:28.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:35:28.253+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:35:28.253+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:35:28.492+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:35:28.487+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:35:28.493+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:35:28.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.257 seconds
[2025-03-18T14:35:58.700+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:35:58.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:35:58.702+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:35:58.701+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:35:58.946+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:35:58.936+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:35:58.947+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:35:58.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.267 seconds
[2025-03-18T14:36:29.198+0000] {processor.py:157} INFO - Started process (PID=107) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:36:29.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:36:29.200+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:36:29.200+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:36:29.404+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:36:29.399+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:36:29.405+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:36:29.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.221 seconds
[2025-03-18T14:36:59.602+0000] {processor.py:157} INFO - Started process (PID=109) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:36:59.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:36:59.604+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:36:59.603+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:37:00.028+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:36:59.995+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:37:00.030+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:37:00.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.444 seconds
[2025-03-18T14:37:30.208+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:37:30.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:37:30.210+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:37:30.210+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:37:30.420+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:37:30.415+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:37:30.421+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:37:30.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.231 seconds
[2025-03-18T14:38:00.615+0000] {processor.py:157} INFO - Started process (PID=113) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:38:00.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:38:00.616+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:38:00.616+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:38:00.825+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:38:00.820+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:38:00.826+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:38:00.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.232 seconds
[2025-03-18T14:38:31.014+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:38:31.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:38:31.016+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:38:31.016+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:38:31.226+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:38:31.221+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:38:31.227+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:38:31.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.228 seconds
[2025-03-18T14:39:01.437+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:39:01.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:39:01.439+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:39:01.439+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:39:01.654+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:39:01.648+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:39:01.655+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:39:01.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.233 seconds
[2025-03-18T14:39:31.859+0000] {processor.py:157} INFO - Started process (PID=119) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:39:31.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:39:31.861+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:39:31.861+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:39:32.087+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:39:32.080+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:39:32.088+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:39:32.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.246 seconds
[2025-03-18T14:40:02.257+0000] {processor.py:157} INFO - Started process (PID=121) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:40:02.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:40:02.258+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:40:02.258+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:40:02.470+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:40:02.464+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:40:02.473+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:40:02.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.232 seconds
[2025-03-18T14:40:32.694+0000] {processor.py:157} INFO - Started process (PID=123) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:40:32.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:40:32.696+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:40:32.695+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:40:32.899+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:40:32.894+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:40:32.900+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:40:32.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.221 seconds
[2025-03-18T14:41:03.069+0000] {processor.py:157} INFO - Started process (PID=125) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:41:03.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:41:03.071+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:41:03.071+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:41:03.289+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:41:03.283+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:41:03.290+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:41:03.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.235 seconds
[2025-03-18T14:41:33.465+0000] {processor.py:157} INFO - Started process (PID=127) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:41:33.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:41:33.467+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:41:33.466+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:41:33.699+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:41:33.694+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:41:33.701+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:41:33.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.253 seconds
[2025-03-18T14:42:03.922+0000] {processor.py:157} INFO - Started process (PID=129) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:42:03.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:42:03.924+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:42:03.924+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:42:04.134+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:42:04.128+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:42:04.135+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:42:04.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.229 seconds
[2025-03-18T14:42:34.328+0000] {processor.py:157} INFO - Started process (PID=131) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:42:34.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:42:34.329+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:42:34.329+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:42:34.544+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:42:34.539+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:42:34.545+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:42:34.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.234 seconds
[2025-03-18T14:43:04.762+0000] {processor.py:157} INFO - Started process (PID=133) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:43:04.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:43:04.763+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:43:04.763+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:43:04.995+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:43:04.989+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:43:04.997+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:43:05.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.253 seconds
[2025-03-18T14:43:35.172+0000] {processor.py:157} INFO - Started process (PID=135) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:43:35.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:43:35.173+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:43:35.173+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:43:35.413+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:43:35.407+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:43:35.414+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:43:35.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.259 seconds
[2025-03-18T14:44:05.586+0000] {processor.py:157} INFO - Started process (PID=137) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:44:05.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:44:05.587+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:44:05.587+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:44:05.802+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:44:05.797+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:44:05.804+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:44:05.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.236 seconds
[2025-03-18T14:44:36.045+0000] {processor.py:157} INFO - Started process (PID=139) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:44:36.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:44:36.047+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:44:36.047+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:44:36.379+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:44:36.371+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:44:36.381+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:44:36.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.355 seconds
[2025-03-18T14:45:06.555+0000] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:45:06.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:45:06.556+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:45:06.556+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:45:06.774+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:45:06.768+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:45:06.775+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:45:06.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.236 seconds
[2025-03-18T14:45:36.906+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:45:36.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:45:36.908+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:45:36.907+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:45:37.123+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:45:37.118+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:45:37.124+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:45:37.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.236 seconds
[2025-03-18T14:46:07.174+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:07.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:46:07.176+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:46:07.176+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:07.391+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:46:07.384+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:46:07.392+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:07.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.234 seconds
[2025-03-18T14:46:22.958+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:22.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:46:22.960+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:46:22.959+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:23.836+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:46:23.832+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:46:23.838+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:23.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.885 seconds
[2025-03-18T14:46:54.094+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:54.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:46:54.096+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:46:54.096+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:54.459+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:46:54.455+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:46:54.460+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:46:54.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.384 seconds
[2025-03-18T14:47:24.687+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:47:24.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:47:24.688+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:47:24.688+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:47:25.264+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:47:25.253+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:47:25.266+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:47:25.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.597 seconds
[2025-03-18T14:47:55.476+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:47:55.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:47:55.477+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:47:55.477+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:47:55.781+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:47:55.778+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:47:55.782+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:47:55.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.322 seconds
[2025-03-18T14:48:26.065+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:48:26.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:48:26.067+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:48:26.067+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:48:26.412+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:48:26.406+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:48:26.413+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:48:26.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.365 seconds
[2025-03-18T14:48:56.636+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:48:56.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:48:56.638+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:48:56.638+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:48:56.990+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:48:56.986+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:48:56.991+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:48:57.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.370 seconds
[2025-03-18T14:49:27.182+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:49:27.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:49:27.184+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:49:27.184+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:49:27.539+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:49:27.532+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:49:27.540+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:49:27.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.371 seconds
[2025-03-18T14:49:57.790+0000] {processor.py:157} INFO - Started process (PID=69) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:49:57.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:49:57.800+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:49:57.799+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:49:58.305+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:49:58.281+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:49:58.308+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:49:58.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.534 seconds
[2025-03-18T14:50:28.537+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:50:28.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:50:28.539+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:50:28.539+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:50:28.880+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:50:28.874+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:50:28.881+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:50:28.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.361 seconds
[2025-03-18T14:50:59.099+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:50:59.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:50:59.100+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:50:59.100+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:50:59.432+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:50:59.427+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:50:59.433+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:50:59.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.356 seconds
[2025-03-18T14:51:29.614+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:51:29.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:51:29.616+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:51:29.616+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:51:29.945+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:51:29.941+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:51:29.946+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:51:29.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.346 seconds
[2025-03-18T14:52:00.130+0000] {processor.py:157} INFO - Started process (PID=89) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:52:00.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:52:00.131+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:52:00.131+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:52:00.444+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:52:00.440+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:52:00.446+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:52:00.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.331 seconds
[2025-03-18T14:52:30.637+0000] {processor.py:157} INFO - Started process (PID=91) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:52:30.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:52:30.638+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:52:30.638+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:52:30.944+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:52:30.940+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:52:30.945+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:52:30.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.322 seconds
[2025-03-18T14:53:01.160+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:53:01.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:53:01.161+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:53:01.161+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:53:01.479+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:53:01.474+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:53:01.480+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:53:01.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.336 seconds
[2025-03-18T14:53:31.676+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:53:31.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:53:31.678+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:53:31.678+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:53:32.031+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:53:32.026+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:53:32.032+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:53:32.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.372 seconds
[2025-03-18T14:54:02.256+0000] {processor.py:157} INFO - Started process (PID=97) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:54:02.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:54:02.258+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:54:02.257+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:54:02.571+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:54:02.568+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:54:02.572+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:54:02.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.330 seconds
[2025-03-18T14:54:32.779+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:54:32.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:54:32.780+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:54:32.780+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:54:33.097+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:54:33.092+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:54:33.098+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:54:33.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.332 seconds
[2025-03-18T14:55:03.295+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:55:03.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:55:03.298+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:55:03.297+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:55:03.672+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:55:03.663+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:55:03.674+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:55:03.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.396 seconds
[2025-03-18T14:55:33.870+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:55:33.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:55:33.871+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:55:33.871+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:55:34.183+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:55:34.179+0000] {dagbag.py:346} ERROR - Failed to import: /opt/airflow/dags/etl_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_dags.py", line 6, in <module>
    from scripts.load import load_data
  File "/opt/airflow/dags/scripts/load.py", line 13, in <module>
    conn = psycopg2.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server on socket "/var/run/postgresql/.s.PGSQL.14694" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?
[2025-03-18T14:55:34.184+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:55:34.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.328 seconds
[2025-03-18T14:56:07.296+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:56:07.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:56:07.300+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:07.300+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:56:10.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:56:10.702+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:10.702+0000] {manager.py:499} INFO - Created Permission View: %s
[2025-03-18T14:56:10.707+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:10.707+0000] {manager.py:499} INFO - Created Permission View: %s
[2025-03-18T14:56:10.711+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:10.711+0000] {manager.py:499} INFO - Created Permission View: %s
[2025-03-18T14:56:10.712+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:10.711+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T14:56:10.718+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:10.718+0000] {dag.py:2963} INFO - Creating ORM DAG for etl_pipeline
[2025-03-18T14:56:10.724+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:10.724+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T13:00:00+00:00, run_after=2025-03-18T14:00:00+00:00
[2025-03-18T14:56:10.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.442 seconds
[2025-03-18T14:56:40.909+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:56:40.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:56:40.913+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:40.912+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:56:43.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:56:43.387+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:43.387+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T14:56:43.403+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:56:43.403+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T13:00:00+00:00, run_after=2025-03-18T14:00:00+00:00
[2025-03-18T14:56:43.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.510 seconds
[2025-03-18T14:57:13.611+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:57:13.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:57:13.612+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:57:13.612+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:57:17.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:57:17.708+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:57:17.708+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T14:57:17.722+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:57:17.722+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T13:00:00+00:00, run_after=2025-03-18T14:00:00+00:00
[2025-03-18T14:57:17.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 4.129 seconds
[2025-03-18T14:58:03.248+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:58:03.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:58:03.250+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:58:03.250+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:58:05.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:58:05.586+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:58:05.586+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T14:58:05.604+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:58:05.604+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T13:00:00+00:00, run_after=2025-03-18T14:00:00+00:00
[2025-03-18T14:58:05.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.372 seconds
[2025-03-18T14:58:35.799+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:58:35.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:58:35.801+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:58:35.801+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:58:38.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:58:38.466+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:58:38.465+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T14:58:38.595+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:58:38.595+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T13:00:00+00:00, run_after=2025-03-18T14:00:00+00:00
[2025-03-18T14:58:38.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.813 seconds
[2025-03-18T14:59:08.674+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:59:08.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:59:08.676+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:59:08.675+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:59:10.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:59:10.588+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:59:10.588+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T14:59:10.695+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:59:10.695+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T13:00:00+00:00, run_after=2025-03-18T14:00:00+00:00
[2025-03-18T14:59:10.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.041 seconds
[2025-03-18T14:59:40.839+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T14:59:40.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T14:59:40.841+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:59:40.841+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:59:42.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T14:59:42.438+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:59:42.438+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T14:59:42.453+0000] {logging_mixin.py:154} INFO - [2025-03-18T14:59:42.453+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T13:00:00+00:00, run_after=2025-03-18T14:00:00+00:00
[2025-03-18T14:59:42.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.630 seconds
[2025-03-18T15:00:12.643+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:00:12.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:00:12.645+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:00:12.645+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:00:15.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:00:15.200+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:00:15.199+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:00:15.213+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:00:15.213+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:00:15.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.589 seconds
[2025-03-18T15:00:45.397+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:00:45.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:00:45.398+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:00:45.398+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:00:47.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:00:48.006+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:00:48.006+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:00:48.021+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:00:48.021+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:00:48.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.732 seconds
[2025-03-18T15:01:18.346+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:01:18.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:01:18.349+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:01:18.348+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:01:21.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:01:21.891+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:01:21.891+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:01:22.000+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:01:22.000+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:01:22.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.669 seconds
[2025-03-18T15:01:52.198+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:01:52.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:01:52.199+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:01:52.199+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:01:54.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:01:54.427+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:01:54.427+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:01:54.547+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:01:54.547+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:01:54.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.397 seconds
[2025-03-18T15:02:24.765+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:02:24.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:02:24.767+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:02:24.766+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:02:26.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:02:26.945+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:02:26.944+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:02:26.958+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:02:26.958+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:02:26.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.211 seconds
[2025-03-18T15:02:57.210+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:02:57.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:02:57.211+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:02:57.211+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:03:00.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:03:00.474+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:03:00.473+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:03:00.490+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:03:00.489+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:03:00.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.297 seconds
[2025-03-18T15:03:30.699+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:03:30.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:03:30.700+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:03:30.700+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:03:31.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:03:31.983+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:03:31.983+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:03:31.998+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:03:31.998+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:03:32.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.318 seconds
[2025-03-18T15:04:02.191+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:04:02.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:04:02.193+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:04:02.193+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:04:04.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:04:04.675+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:04:04.675+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:04:04.785+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:04:04.784+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:04:04.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.614 seconds
[2025-03-18T15:04:34.973+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:04:34.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:04:34.974+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:04:34.974+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:04:36.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:04:36.756+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:04:36.756+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:04:36.858+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:04:36.858+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:04:36.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.901 seconds
[2025-03-18T15:05:07.077+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:05:07.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:05:07.078+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:05:07.078+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:05:09.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:05:09.629+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:05:09.629+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:05:09.742+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:05:09.742+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:05:09.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.691 seconds
[2025-03-18T15:05:39.954+0000] {processor.py:157} INFO - Started process (PID=113) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:05:39.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:05:39.955+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:05:39.955+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:05:41.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:05:41.697+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:05:41.697+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:05:41.711+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:05:41.711+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:05:41.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.774 seconds
[2025-03-18T15:06:11.930+0000] {processor.py:157} INFO - Started process (PID=122) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:06:11.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:06:11.932+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:06:11.931+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:06:13.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:06:13.860+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:06:13.860+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:06:13.877+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:06:13.877+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:06:13.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.965 seconds
[2025-03-18T15:06:44.149+0000] {processor.py:157} INFO - Started process (PID=124) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:06:44.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:06:44.151+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:06:44.151+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:06:46.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:06:46.492+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:06:46.492+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:06:46.508+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:06:46.508+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:06:46.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.380 seconds
[2025-03-18T15:07:16.726+0000] {processor.py:157} INFO - Started process (PID=133) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:07:16.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:07:16.728+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:07:16.728+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:07:18.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:07:18.070+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:07:18.070+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:07:18.189+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:07:18.188+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:07:18.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.482 seconds
[2025-03-18T15:07:48.438+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:07:48.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:07:48.440+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:07:48.440+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:07:49.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:07:49.424+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:07:49.424+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:07:49.525+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:07:49.525+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:07:49.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.107 seconds
[2025-03-18T15:08:19.779+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:08:19.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:08:19.780+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:08:19.780+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:08:20.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:08:21.092+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:08:21.092+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:08:21.107+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:08:21.106+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:08:21.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.349 seconds
[2025-03-18T15:08:51.310+0000] {processor.py:157} INFO - Started process (PID=191) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:08:51.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:08:51.311+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:08:51.311+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:08:52.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:08:52.351+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:08:52.351+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:08:52.368+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:08:52.368+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:08:52.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.074 seconds
[2025-03-18T15:09:22.487+0000] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:09:22.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:09:22.491+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:09:22.491+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:09:23.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:09:23.713+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:09:23.712+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:09:23.730+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:09:23.730+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:09:23.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.266 seconds
[2025-03-18T15:09:54.314+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:09:54.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:09:54.316+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:09:54.316+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:09:57.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:09:57.044+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:09:57.044+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:09:57.058+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:09:57.058+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:09:57.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.858 seconds
[2025-03-18T15:10:27.367+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:10:27.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:10:27.368+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:10:27.368+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:10:28.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:10:28.502+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:10:28.502+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:10:28.609+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:10:28.609+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:10:28.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.260 seconds
[2025-03-18T15:10:58.874+0000] {processor.py:157} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:10:58.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:10:58.876+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:10:58.876+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:00.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:00.320+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:00.319+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:11:00.431+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:00.431+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:11:00.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.574 seconds
[2025-03-18T15:11:09.674+0000] {processor.py:157} INFO - Started process (PID=37) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:09.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:11:09.676+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:09.676+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:10.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:10.641+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:10.641+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:11:10.656+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:10.655+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:11:10.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.997 seconds
[2025-03-18T15:11:40.851+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:40.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:11:40.853+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:40.853+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:42.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:11:42.738+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:42.738+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:11:42.833+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:11:42.833+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:11:42.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.999 seconds
[2025-03-18T15:12:13.100+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:12:13.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:12:13.101+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:12:13.101+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:12:14.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:12:14.371+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:12:14.370+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:12:14.472+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:12:14.472+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:12:14.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.391 seconds
[2025-03-18T15:12:53.056+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:12:53.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:12:53.058+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:12:53.058+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:12:54.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:12:54.981+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:12:54.981+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:12:54.994+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:12:54.994+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:12:55.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.955 seconds
[2025-03-18T15:13:25.189+0000] {processor.py:157} INFO - Started process (PID=45) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:13:25.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:13:25.190+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:13:25.190+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:13:26.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:13:26.342+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:13:26.342+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:13:26.357+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:13:26.357+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:13:26.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.184 seconds
[2025-03-18T15:13:56.422+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:13:56.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:13:56.423+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:13:56.423+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:13:57.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:13:57.530+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:13:57.530+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:13:57.547+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:13:57.547+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:13:57.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.143 seconds
[2025-03-18T15:14:27.823+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:14:27.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:14:27.825+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:14:27.825+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:14:28.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:14:28.948+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:14:28.947+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:14:28.962+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:14:28.962+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:14:28.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.159 seconds
[2025-03-18T15:14:59.041+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:14:59.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:14:59.042+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:14:59.042+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:15:00.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:15:00.126+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:15:00.126+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:15:00.140+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:15:00.140+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:15:00.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.121 seconds
[2025-03-18T15:15:30.210+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:15:30.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:15:30.211+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:15:30.211+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:15:31.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:15:31.225+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:15:31.225+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:15:31.239+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:15:31.239+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:15:31.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.047 seconds
[2025-03-18T15:16:01.504+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:16:01.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:16:01.506+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:16:01.505+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:16:02.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:16:02.594+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:16:02.594+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:16:02.610+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:16:02.610+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:16:02.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.123 seconds
[2025-03-18T15:16:32.700+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:16:32.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:16:32.701+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:16:32.701+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:16:33.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:16:33.844+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:16:33.843+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:16:33.860+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:16:33.860+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:16:33.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.176 seconds
[2025-03-18T15:17:04.035+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:17:04.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:17:04.038+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:17:04.038+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:17:05.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:17:05.297+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:17:05.297+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:17:05.310+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:17:05.310+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:17:05.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.293 seconds
[2025-03-18T15:17:35.558+0000] {processor.py:157} INFO - Started process (PID=127) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:17:35.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:17:35.559+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:17:35.559+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:17:36.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:17:36.776+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:17:36.775+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:17:36.794+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:17:36.793+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:17:36.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.253 seconds
[2025-03-18T15:18:07.068+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:18:07.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:18:07.070+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:18:07.070+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:18:08.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:18:08.325+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:18:08.325+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:18:08.338+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:18:08.338+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:18:08.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.289 seconds
[2025-03-18T15:18:38.641+0000] {processor.py:157} INFO - Started process (PID=168) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:18:38.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:18:38.642+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:18:38.642+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:18:39.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:18:39.850+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:18:39.850+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:18:39.863+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:18:39.863+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:18:39.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.242 seconds
[2025-03-18T15:19:10.128+0000] {processor.py:157} INFO - Started process (PID=170) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:19:10.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:19:10.129+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:19:10.129+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:19:11.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:19:11.921+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:19:11.921+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:19:11.937+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:19:11.937+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:19:11.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.826 seconds
[2025-03-18T15:19:42.006+0000] {processor.py:157} INFO - Started process (PID=196) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:19:42.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:19:42.008+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:19:42.008+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:19:43.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:19:43.042+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:19:43.042+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:19:43.056+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:19:43.055+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:19:43.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.068 seconds
[2025-03-18T15:20:19.067+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:20:19.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:20:19.068+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:20:19.068+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:20:20.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:20:20.946+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:20:20.946+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:20:20.959+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:20:20.959+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:20:20.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.911 seconds
[2025-03-18T15:20:51.207+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:20:51.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:20:51.209+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:20:51.209+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:20:52.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:20:52.725+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:20:52.725+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:20:52.836+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:20:52.835+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:20:52.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.645 seconds
[2025-03-18T15:21:23.035+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:21:23.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:21:23.036+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:21:23.036+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:21:23.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:21:23.967+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:21:23.967+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:21:24.064+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:21:24.064+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:21:24.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.049 seconds
[2025-03-18T15:21:54.214+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:21:54.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:21:54.216+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:21:54.216+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:21:56.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:21:56.410+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:21:56.410+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:21:56.424+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:21:56.424+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:21:56.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.229 seconds
[2025-03-18T15:22:26.650+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:22:26.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:22:26.651+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:22:26.651+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:22:27.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:22:27.740+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:22:27.739+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:22:27.754+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:22:27.754+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:22:27.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.123 seconds
[2025-03-18T15:22:57.851+0000] {processor.py:157} INFO - Started process (PID=97) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:22:57.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:22:57.852+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:22:57.852+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:22:59.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:22:59.018+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:22:59.018+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:22:59.033+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:22:59.033+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:22:59.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.203 seconds
[2025-03-18T15:23:29.119+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:23:29.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:23:29.120+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:23:29.120+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:23:31.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:23:31.708+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:23:31.707+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:23:31.813+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:23:31.812+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:23:31.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.712 seconds
[2025-03-18T15:24:02.113+0000] {processor.py:157} INFO - Started process (PID=124) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:24:02.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:24:02.115+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:24:02.114+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:24:04.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:24:04.130+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:24:04.129+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:24:04.244+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:24:04.244+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:24:04.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.147 seconds
[2025-03-18T15:24:34.305+0000] {processor.py:157} INFO - Started process (PID=140) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:24:34.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:24:34.306+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:24:34.306+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:24:36.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:24:36.975+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:24:36.974+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:24:36.988+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:24:36.988+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:24:37.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.699 seconds
[2025-03-18T15:25:07.167+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:25:07.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:25:07.168+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:25:07.168+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:25:08.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:25:08.821+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:25:08.820+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:25:08.836+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:25:08.835+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:25:08.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.715 seconds
[2025-03-18T15:25:39.266+0000] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:25:39.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:25:39.268+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:25:39.268+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:25:41.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:25:41.331+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:25:41.331+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:25:41.347+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:25:41.347+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:25:41.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.099 seconds
[2025-03-18T15:26:11.445+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:26:11.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:26:11.447+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:26:11.447+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:26:13.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:26:13.952+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:26:13.952+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:26:13.968+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:26:13.967+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:26:14.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.629 seconds
[2025-03-18T15:26:44.339+0000] {processor.py:157} INFO - Started process (PID=220) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:26:44.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:26:44.341+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:26:44.340+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:26:45.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:26:45.382+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:26:45.381+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:26:45.481+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:26:45.481+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:26:45.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.159 seconds
[2025-03-18T15:27:15.619+0000] {processor.py:157} INFO - Started process (PID=229) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:27:15.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:27:15.621+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:27:15.621+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:27:16.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:27:16.625+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:27:16.624+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:27:16.738+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:27:16.738+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:27:16.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.138 seconds
[2025-03-18T15:27:28.519+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:27:28.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:27:28.521+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:27:28.521+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:27:29.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:27:29.869+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:27:29.869+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:27:29.883+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:27:29.883+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:27:29.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.382 seconds
[2025-03-18T15:28:00.110+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:28:00.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:28:00.111+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:28:00.111+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:28:01.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:28:01.187+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:28:01.186+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:28:01.302+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:28:01.301+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:28:01.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.210 seconds
[2025-03-18T15:28:31.353+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:28:31.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:28:31.355+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:28:31.355+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:28:32.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:28:32.354+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:28:32.354+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:28:32.462+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:28:32.462+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:28:32.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.125 seconds
[2025-03-18T15:29:02.534+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:29:02.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:29:02.535+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:29:02.535+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:29:03.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:29:03.659+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:29:03.659+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:29:03.665+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:29:03.665+0000] {dag.py:2963} INFO - Creating ORM DAG for etl_pipeline
[2025-03-18T15:29:03.671+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:29:03.671+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:29:03.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.154 seconds
[2025-03-18T15:29:33.858+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:29:33.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:29:33.860+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:29:33.859+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:29:35.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:29:35.542+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:29:35.542+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:29:35.557+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:29:35.557+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:29:35.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.719 seconds
[2025-03-18T15:30:05.774+0000] {processor.py:157} INFO - Started process (PID=124) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:30:05.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:30:05.776+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:30:05.776+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:30:06.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:30:06.868+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:30:06.868+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:30:06.883+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:30:06.883+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:30:06.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.131 seconds
[2025-03-18T15:30:37.008+0000] {processor.py:157} INFO - Started process (PID=133) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:30:37.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:30:37.010+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:30:37.009+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:30:38.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:30:38.068+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:30:38.067+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:30:38.171+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:30:38.170+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:30:38.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.183 seconds
[2025-03-18T15:31:08.257+0000] {processor.py:157} INFO - Started process (PID=135) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:31:08.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:31:08.263+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:31:08.263+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:31:09.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:31:09.635+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:31:09.634+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:31:09.780+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:31:09.780+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:31:09.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.541 seconds
[2025-03-18T15:32:50.383+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:32:50.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:32:50.385+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:32:50.385+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:32:51.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:32:51.944+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:32:51.944+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:32:51.957+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:32:51.957+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:32:51.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.592 seconds
[2025-03-18T15:33:22.128+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:33:22.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:33:22.129+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:33:22.129+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:33:27.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:33:27.303+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:33:27.303+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:33:27.316+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:33:27.315+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:33:27.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 5.207 seconds
[2025-03-18T15:33:57.513+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:33:57.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:33:57.515+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:33:57.515+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:34:00.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:34:00.982+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:34:00.982+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:34:00.996+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:34:00.996+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:34:01.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.496 seconds
[2025-03-18T15:34:31.230+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:34:31.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:34:31.232+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:34:31.232+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:34:32.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:34:32.590+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:34:32.590+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:34:32.605+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:34:32.605+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:34:32.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.392 seconds
[2025-03-18T15:35:02.807+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:35:02.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:35:02.809+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:35:02.809+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:35:03.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:35:03.944+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:35:03.944+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:35:03.959+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:35:03.959+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:35:03.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.172 seconds
[2025-03-18T15:35:34.130+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:35:34.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:35:34.132+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:35:34.131+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:35:35.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:35:35.338+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:35:35.338+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:35:35.353+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:35:35.353+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:35:35.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.334 seconds
[2025-03-18T15:36:05.657+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:36:05.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:36:05.659+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:36:05.659+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:36:06.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:36:06.668+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:36:06.668+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:36:06.770+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:36:06.769+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:36:06.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.133 seconds
[2025-03-18T15:36:36.839+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:36:36.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:36:36.840+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:36:36.840+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:36:37.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:36:37.996+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:36:37.996+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:36:38.089+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:36:38.089+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:36:38.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.269 seconds
[2025-03-18T15:37:08.240+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:37:08.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:37:08.241+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:37:08.241+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:37:09.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:37:09.736+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:37:09.736+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:37:09.749+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:37:09.749+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:37:09.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.529 seconds
[2025-03-18T15:37:39.967+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:37:39.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:37:39.968+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:37:39.968+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:37:41.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:37:41.101+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:37:41.101+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:37:41.115+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:37:41.115+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:37:41.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.169 seconds
[2025-03-18T15:38:11.161+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:38:11.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:38:11.163+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:38:11.162+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:38:12.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:38:12.549+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:38:12.548+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:38:12.562+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:38:12.562+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:38:12.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.420 seconds
[2025-03-18T15:38:42.618+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:38:42.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:38:42.619+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:38:42.619+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:38:43.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:38:43.604+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:38:43.603+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:38:43.618+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:38:43.618+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:38:43.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.104 seconds
[2025-03-18T15:39:13.894+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:39:13.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:39:13.895+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:39:13.895+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:39:15.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:39:15.027+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:39:15.027+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:39:15.119+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:39:15.119+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:39:15.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.243 seconds
[2025-03-18T15:39:45.316+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:39:45.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:39:45.317+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:39:45.317+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:39:46.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:39:46.324+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:39:46.323+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:39:46.461+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:39:46.461+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:39:46.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.161 seconds
[2025-03-18T15:40:16.642+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:40:16.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:40:16.643+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:40:16.643+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:40:17.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:40:17.919+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:40:17.918+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:40:17.934+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:40:17.933+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:40:17.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.312 seconds
[2025-03-18T15:40:48.175+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:40:48.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:40:48.177+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:40:48.177+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:40:49.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:40:49.207+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:40:49.207+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:40:49.223+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:40:49.223+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:40:49.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.067 seconds
[2025-03-18T15:41:19.328+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:41:19.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:41:19.329+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:41:19.329+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:41:20.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:41:20.408+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:41:20.408+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:41:20.424+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:41:20.424+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:41:20.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.115 seconds
[2025-03-18T15:41:50.644+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:41:50.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:41:50.646+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:41:50.646+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:41:51.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:41:51.722+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:41:51.721+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:41:51.738+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:41:51.738+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:41:51.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.211 seconds
[2025-03-18T15:42:21.896+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:42:21.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:42:21.897+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:42:21.897+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:42:22.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:42:22.988+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:42:22.988+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:42:23.083+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:42:23.082+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:42:23.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.206 seconds
[2025-03-18T15:42:53.181+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:42:53.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:42:53.183+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:42:53.183+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:42:54.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:42:54.296+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:42:54.296+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:42:54.399+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:42:54.399+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:42:54.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.236 seconds
[2025-03-18T15:43:24.594+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:43:24.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:43:24.596+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:43:24.596+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:43:26.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:43:26.073+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:43:26.073+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:43:26.089+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:43:26.089+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:43:26.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.516 seconds
[2025-03-18T15:43:56.281+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:43:56.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:43:56.283+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:43:56.283+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:43:57.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:43:57.971+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:43:57.971+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:43:57.985+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:43:57.985+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:43:58.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.724 seconds
[2025-03-18T15:44:28.229+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:44:28.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:44:28.231+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:44:28.231+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:44:29.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:44:29.362+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:44:29.362+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:44:29.375+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:44:29.375+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:44:29.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.171 seconds
[2025-03-18T15:44:59.585+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:44:59.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:44:59.587+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:44:59.586+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:45:00.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:45:00.838+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:45:00.838+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:45:00.938+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:45:00.938+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:45:00.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.379 seconds
[2025-03-18T15:45:31.172+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:45:31.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:45:31.174+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:45:31.173+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:45:32.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:45:32.166+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:45:32.166+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:45:32.260+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:45:32.260+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:45:32.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.106 seconds
[2025-03-18T15:46:02.503+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:46:02.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:46:02.505+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:46:02.505+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:46:08.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:46:08.327+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:46:08.327+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:46:08.433+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:46:08.433+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:46:08.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 5.960 seconds
[2025-03-18T15:46:38.668+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:46:38.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:46:38.672+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:46:38.671+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:46:40.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:46:40.475+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:46:40.474+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:46:40.488+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:46:40.488+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:46:40.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.837 seconds
[2025-03-18T15:47:10.713+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:47:10.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:47:10.714+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:47:10.714+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:47:12.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:47:12.993+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:47:12.993+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:47:13.007+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:47:13.007+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:47:13.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.311 seconds
[2025-03-18T15:47:43.133+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:47:43.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:47:43.135+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:47:43.134+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:47:44.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:47:44.490+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:47:44.490+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:47:44.505+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:47:44.505+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:47:44.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.484 seconds
[2025-03-18T15:48:14.905+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:48:14.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:48:14.907+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:48:14.907+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:48:16.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:48:16.938+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:48:16.938+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:48:17.033+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:48:17.033+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:48:17.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.146 seconds
[2025-03-18T15:48:47.081+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:48:47.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:48:47.083+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:48:47.083+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:48:49.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:48:49.268+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:48:49.268+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:48:49.365+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:48:49.365+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:48:49.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.298 seconds
[2025-03-18T15:49:19.544+0000] {processor.py:157} INFO - Started process (PID=98) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:49:19.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:49:19.546+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:49:19.545+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:49:21.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:49:21.441+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:49:21.440+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:49:21.454+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:49:21.454+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:49:21.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.925 seconds
[2025-03-18T15:49:51.538+0000] {processor.py:157} INFO - Started process (PID=100) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:49:51.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:49:51.540+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:49:51.540+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:49:53.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:49:53.231+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:49:53.231+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:49:53.247+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:49:53.247+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:49:53.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.726 seconds
[2025-03-18T15:50:23.490+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:50:23.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:50:23.492+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:50:23.492+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:50:25.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:50:25.168+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:50:25.168+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:50:25.182+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:50:25.182+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:50:25.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.719 seconds
[2025-03-18T15:50:55.399+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:50:55.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:50:55.401+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:50:55.401+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:50:56.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:50:56.862+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:50:56.862+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:50:56.959+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:50:56.959+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:50:56.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.575 seconds
[2025-03-18T15:51:27.145+0000] {processor.py:157} INFO - Started process (PID=106) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:51:27.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:51:27.147+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:51:27.147+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:51:29.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:51:29.374+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:51:29.374+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:51:29.478+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:51:29.478+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:51:29.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.349 seconds
[2025-03-18T15:51:59.718+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:51:59.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:51:59.720+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:51:59.720+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:52:01.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:52:01.384+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:52:01.383+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:52:01.398+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:52:01.398+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:52:01.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.697 seconds
[2025-03-18T15:52:31.499+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:52:31.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:52:31.501+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:52:31.501+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:52:33.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:52:33.210+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:52:33.210+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:52:33.228+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:52:33.228+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:52:33.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.745 seconds
[2025-03-18T15:53:03.448+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:03.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:53:03.450+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:03.449+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:04.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:04.710+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:04.710+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:53:04.725+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:04.725+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:53:04.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.295 seconds
[2025-03-18T15:53:35.160+0000] {processor.py:157} INFO - Started process (PID=114) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:35.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:53:35.177+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:35.176+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:37.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:37.104+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:37.103+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:53:37.208+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:37.208+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:53:37.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.065 seconds
[2025-03-18T15:53:47.641+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:47.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:53:47.643+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:47.643+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:49.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:53:49.474+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:49.474+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:53:49.488+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:53:49.488+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:53:49.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.862 seconds
[2025-03-18T15:54:19.718+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:54:19.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:54:19.720+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:54:19.720+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:54:21.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:54:21.210+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:54:21.209+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:54:21.224+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:54:21.224+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:54:21.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.525 seconds
[2025-03-18T15:55:50.371+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:55:50.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:55:50.373+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:55:50.372+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:55:51.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:55:51.986+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:55:51.986+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:55:52.001+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:55:52.001+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:55:52.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.651 seconds
[2025-03-18T15:56:22.224+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:56:22.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:56:22.227+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:56:22.227+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:56:23.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:56:23.691+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:56:23.691+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:56:23.814+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:56:23.814+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:56:23.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.608 seconds
[2025-03-18T15:56:53.984+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:56:53.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:56:53.986+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:56:53.986+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:56:55.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:56:55.732+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:56:55.732+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:56:55.841+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:56:55.841+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:56:55.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.874 seconds
[2025-03-18T15:57:25.897+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:57:25.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:57:25.900+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:57:25.900+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:57:27.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:57:27.514+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:57:27.514+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:57:27.529+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:57:27.529+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:57:27.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.649 seconds
[2025-03-18T15:57:57.750+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:57:57.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:57:57.751+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:57:57.751+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:00.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:00.358+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:00.357+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:58:00.377+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:00.377+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:58:00.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.648 seconds
[2025-03-18T15:58:30.604+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:30.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:58:30.606+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:30.606+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:34.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:34.355+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:34.355+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:58:34.372+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:34.371+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:58:34.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.879 seconds
[2025-03-18T15:58:53.088+0000] {processor.py:157} INFO - Started process (PID=37) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:53.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:58:53.089+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:53.089+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:55.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:58:55.491+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:55.491+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:58:55.507+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:58:55.506+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:58:55.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.438 seconds
[2025-03-18T15:59:25.808+0000] {processor.py:157} INFO - Started process (PID=39) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:59:25.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:59:25.810+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:59:25.810+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:59:28.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T15:59:28.146+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:59:28.145+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T15:59:28.265+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:59:28.264+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T14:00:00+00:00, run_after=2025-03-18T15:00:00+00:00
[2025-03-18T15:59:28.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.474 seconds
[2025-03-18T15:59:58.455+0000] {processor.py:157} INFO - Started process (PID=41) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T15:59:58.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T15:59:58.456+0000] {logging_mixin.py:154} INFO - [2025-03-18T15:59:58.456+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:00:00.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:00:00.530+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:00.530+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:00:00.636+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:00.636+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:00:00.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.203 seconds
[2025-03-18T16:00:51.350+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:00:51.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:00:51.351+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:51.351+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:00:54.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:00:54.793+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:54.793+0000] {manager.py:499} INFO - Created Permission View: %s
[2025-03-18T16:00:54.802+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:54.801+0000] {manager.py:499} INFO - Created Permission View: %s
[2025-03-18T16:00:54.810+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:54.810+0000] {manager.py:499} INFO - Created Permission View: %s
[2025-03-18T16:00:54.811+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:54.811+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:00:54.820+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:54.820+0000] {dag.py:2963} INFO - Creating ORM DAG for etl_pipeline
[2025-03-18T16:00:54.828+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:00:54.828+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:00:54.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.499 seconds
[2025-03-18T16:01:25.171+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:01:25.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:01:25.173+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:01:25.173+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:01:27.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:01:27.820+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:01:27.819+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:01:27.844+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:01:27.844+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:01:27.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.696 seconds
[2025-03-18T16:01:58.032+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:01:58.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:01:58.034+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:01:58.034+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:02:00.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:02:00.063+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:02:00.063+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:02:00.081+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:02:00.081+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:02:00.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.066 seconds
[2025-03-18T16:02:33.141+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:02:33.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:02:33.143+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:02:33.142+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:02:37.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:02:37.304+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:02:37.304+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:02:37.317+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:02:37.317+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:02:37.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 4.191 seconds
[2025-03-18T16:03:07.418+0000] {processor.py:157} INFO - Started process (PID=38) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:03:07.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:03:07.419+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:03:07.419+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:03:09.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:03:09.044+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:03:09.044+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:03:09.153+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:03:09.153+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:03:09.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.753 seconds
[2025-03-18T16:03:39.398+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:03:39.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:03:39.399+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:03:39.399+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:03:44.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:03:44.206+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:03:44.206+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:03:44.305+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:03:44.305+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:03:44.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 4.928 seconds
[2025-03-18T16:04:14.534+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:04:14.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:04:14.536+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:04:14.536+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:04:16.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:04:16.367+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:04:16.367+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:04:16.384+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:04:16.384+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:04:16.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.869 seconds
[2025-03-18T16:04:46.573+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:04:46.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:04:46.575+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:04:46.575+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:04:48.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:04:48.555+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:04:48.554+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:04:48.571+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:04:48.571+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:04:48.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.016 seconds
[2025-03-18T16:05:18.739+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:05:18.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:05:18.740+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:05:18.740+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:05:21.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:05:21.294+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:05:21.294+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:05:21.310+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:05:21.310+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:05:21.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.677 seconds
[2025-03-18T16:05:38.084+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:05:38.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:05:38.085+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:05:38.085+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:05:39.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:05:39.805+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:05:39.805+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:05:39.819+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:05:39.819+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:05:39.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.753 seconds
[2025-03-18T16:06:10.046+0000] {processor.py:157} INFO - Started process (PID=45) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:06:10.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:06:10.048+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:06:10.048+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:06:12.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:06:12.021+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:06:12.021+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:06:12.121+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:06:12.121+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:06:12.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.092 seconds
[2025-03-18T16:06:42.234+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:06:42.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:06:42.236+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:06:42.235+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:06:44.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:06:44.500+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:06:44.500+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:06:44.606+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:06:44.606+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:06:44.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.389 seconds
[2025-03-18T16:07:14.873+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:07:14.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:07:14.876+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:07:14.876+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:07:18.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:07:18.043+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:07:18.043+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:07:18.060+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:07:18.060+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:07:18.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.204 seconds
[2025-03-18T16:07:48.108+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:07:48.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:07:48.112+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:07:48.112+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:07:49.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:07:49.960+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:07:49.959+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:07:49.976+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:07:49.976+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:07:49.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.888 seconds
[2025-03-18T16:08:20.192+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:08:20.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:08:20.194+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:08:20.194+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:08:23.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:08:23.152+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:08:23.152+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:08:23.168+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:08:23.168+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:08:23.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.084 seconds
[2025-03-18T16:08:53.411+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:08:53.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:08:53.413+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:08:53.413+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:08:55.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:08:55.958+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:08:55.957+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:08:56.059+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:08:56.059+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:08:56.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.668 seconds
[2025-03-18T16:09:26.265+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:09:26.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:09:26.267+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:09:26.267+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:09:31.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:09:31.792+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:09:31.791+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:09:31.902+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:09:31.902+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:09:31.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 5.652 seconds
[2025-03-18T16:10:02.122+0000] {processor.py:157} INFO - Started process (PID=133) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:10:02.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:10:02.123+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:10:02.123+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:10:03.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:10:03.930+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:10:03.930+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:10:03.946+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:10:03.946+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:10:03.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.843 seconds
[2025-03-18T16:10:34.146+0000] {processor.py:157} INFO - Started process (PID=135) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:10:34.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:10:34.147+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:10:34.147+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:10:36.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:10:36.655+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:10:36.655+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:10:36.669+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:10:36.669+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:10:36.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.539 seconds
[2025-03-18T16:11:06.969+0000] {processor.py:157} INFO - Started process (PID=144) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:11:06.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:11:06.971+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:11:06.971+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:11:09.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:11:09.918+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:11:09.918+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:11:09.932+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:11:09.932+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:11:09.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.979 seconds
[2025-03-18T16:11:40.107+0000] {processor.py:157} INFO - Started process (PID=153) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:11:40.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:11:40.109+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:11:40.109+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:11:42.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:11:42.255+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:11:42.254+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:11:42.363+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:11:42.363+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:11:42.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.277 seconds
[2025-03-18T16:12:12.586+0000] {processor.py:157} INFO - Started process (PID=162) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:12:12.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:12:12.588+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:12:12.588+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:12:15.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:12:15.955+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:12:15.954+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:12:16.061+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:12:16.061+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:12:16.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 3.491 seconds
[2025-03-18T16:12:46.253+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:12:46.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:12:46.254+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:12:46.254+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:12:50.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:12:50.185+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:12:50.185+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:12:50.298+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:12:50.298+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:12:50.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 4.062 seconds
[2025-03-18T16:13:20.497+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:13:20.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:13:20.499+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:13:20.499+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:13:22.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:13:22.082+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:13:22.082+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:13:22.097+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:13:22.097+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:13:22.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.615 seconds
[2025-03-18T16:13:52.286+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:13:52.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:13:52.289+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:13:52.289+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:13:53.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:13:53.838+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:13:53.838+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:13:53.855+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:13:53.854+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:13:53.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.585 seconds
[2025-03-18T16:14:23.898+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:14:23.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:14:23.900+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:14:23.899+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:14:28.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:14:28.107+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:14:28.106+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:14:28.121+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:14:28.121+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:14:28.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 4.245 seconds
[2025-03-18T16:14:58.284+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:14:58.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:14:58.286+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:14:58.286+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:14:59.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:15:00.018+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:15:00.018+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:15:00.144+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:15:00.143+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:15:00.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.879 seconds
[2025-03-18T16:15:30.353+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:15:30.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:15:30.355+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:15:30.355+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:15:31.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:15:31.920+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:15:31.920+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:15:32.033+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:15:32.033+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:15:32.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.697 seconds
[2025-03-18T16:16:02.195+0000] {processor.py:157} INFO - Started process (PID=226) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:02.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:16:02.196+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:02.196+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:03.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:03.374+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:03.373+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:16:03.387+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:03.387+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:16:03.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.211 seconds
[2025-03-18T16:16:33.617+0000] {processor.py:157} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:33.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:16:33.618+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:33.618+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:34.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:34.538+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:34.537+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:16:34.554+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:34.554+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:16:34.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.955 seconds
[2025-03-18T16:16:51.508+0000] {processor.py:157} INFO - Started process (PID=230) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:51.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:16:51.510+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:51.509+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:52.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:52.912+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:52.911+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:16:52.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.435 seconds
[2025-03-18T16:16:53.683+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:53.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:16:53.685+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:53.685+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:54.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:16:54.793+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:16:54.792+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:16:54.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.145 seconds
[2025-03-18T16:17:24.895+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:17:24.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:17:24.897+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:17:24.897+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:17:25.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:17:25.805+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:17:25.804+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:17:25.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.044 seconds
[2025-03-18T16:17:55.913+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:17:55.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:17:55.914+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:17:55.914+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:17:56.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:17:56.929+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:17:56.928+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:17:56.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.053 seconds
[2025-03-18T16:18:27.113+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:18:27.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:18:27.114+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:18:27.114+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:18:27.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:18:27.964+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:18:27.964+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:18:28.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.973 seconds
[2025-03-18T16:18:58.332+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:18:58.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:18:58.334+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:18:58.334+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:18:59.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:18:59.909+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:18:59.909+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:19:00.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.703 seconds
[2025-03-18T16:19:30.272+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:19:30.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:19:30.274+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:19:30.273+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:19:31.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:19:31.678+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:19:31.678+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:19:31.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.437 seconds
[2025-03-18T16:20:01.751+0000] {processor.py:157} INFO - Started process (PID=65) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:20:01.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:20:01.753+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:20:01.752+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:20:03.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:20:03.702+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:20:03.701+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:20:03.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.991 seconds
[2025-03-18T16:20:33.933+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:20:33.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:20:33.935+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:20:33.934+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:20:35.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:20:35.246+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:20:35.245+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:20:35.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.349 seconds
[2025-03-18T16:21:05.473+0000] {processor.py:157} INFO - Started process (PID=69) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:21:05.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:21:05.474+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:21:05.474+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:21:07.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:21:07.223+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:21:07.223+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:21:07.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.869 seconds
[2025-03-18T16:21:37.554+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:21:37.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:21:37.555+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:21:37.555+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:21:38.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:21:38.923+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:21:38.922+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:21:39.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.487 seconds
[2025-03-18T16:22:09.224+0000] {processor.py:157} INFO - Started process (PID=73) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:22:09.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:22:09.226+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:22:09.226+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:22:10.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:22:10.416+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:22:10.415+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:22:10.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.220 seconds
[2025-03-18T16:22:40.643+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:22:40.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:22:40.644+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:22:40.644+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:22:41.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:22:41.836+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:22:41.836+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:22:41.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.226 seconds
[2025-03-18T16:23:12.170+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:23:12.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:23:12.172+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:23:12.172+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:23:13.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:23:13.132+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:23:13.132+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:23:13.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.995 seconds
[2025-03-18T16:24:16.690+0000] {processor.py:157} INFO - Started process (PID=43) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:24:16.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:24:16.691+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:24:16.691+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:24:18.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:24:18.654+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:24:18.653+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:24:18.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.994 seconds
[2025-03-18T16:24:48.901+0000] {processor.py:157} INFO - Started process (PID=45) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:24:48.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:24:48.902+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:24:48.902+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:24:50.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:24:50.657+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:24:50.656+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:24:50.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.788 seconds
[2025-03-18T16:25:20.878+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:25:20.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:25:20.880+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:25:20.880+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:25:23.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:25:23.611+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:25:23.611+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:25:23.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.760 seconds
[2025-03-18T16:25:53.846+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:25:53.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:25:53.847+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:25:53.847+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:25:55.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:25:55.104+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:25:55.104+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:25:55.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.289 seconds
[2025-03-18T16:26:25.353+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:26:25.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:26:25.355+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:26:25.355+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:26:26.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:26:26.741+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:26:26.740+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:26:26.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.418 seconds
[2025-03-18T16:26:27.360+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:26:27.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:26:27.362+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:26:27.362+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:26:28.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:26:28.341+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:26:28.340+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:26:28.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.009 seconds
[2025-03-18T16:26:58.540+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:26:58.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:26:58.541+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:26:58.541+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:27:04.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:27:04.388+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:27:04.388+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:27:04.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 5.878 seconds
[2025-03-18T16:27:34.590+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:27:34.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:27:34.591+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:27:34.591+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:27:36.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:27:36.052+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:27:36.052+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:27:36.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.493 seconds
[2025-03-18T16:28:06.247+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:06.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:28:06.249+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:28:06.249+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:07.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:07.843+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:28:07.843+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:28:07.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.624 seconds
[2025-03-18T16:28:38.062+0000] {processor.py:157} INFO - Started process (PID=61) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:38.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:28:38.064+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:28:38.064+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:44.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:44.776+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:28:44.776+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:28:44.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 6.746 seconds
[2025-03-18T16:28:50.288+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:50.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:28:50.289+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:28:50.289+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:52.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:28:53.004+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:28:53.004+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:28:53.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.751 seconds
[2025-03-18T16:29:15.000+0000] {processor.py:157} INFO - Started process (PID=89) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:15.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:29:15.001+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:29:15.001+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:17.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:17.706+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:29:17.706+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:29:17.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.770 seconds
[2025-03-18T16:29:23.232+0000] {processor.py:157} INFO - Started process (PID=91) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:23.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:29:23.233+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:29:23.233+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:25.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:25.123+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:29:25.123+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:29:25.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.024 seconds
[2025-03-18T16:29:47.976+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:47.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:29:47.978+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:29:47.978+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:49.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:29:49.950+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:29:49.950+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:29:49.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.003 seconds
[2025-03-18T16:30:20.165+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:30:20.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:30:20.167+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:30:20.166+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:30:22.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:30:22.140+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:30:22.140+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:30:22.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.005 seconds
[2025-03-18T16:30:52.351+0000] {processor.py:157} INFO - Started process (PID=97) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:30:52.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:30:52.352+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:30:52.352+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:30:54.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:30:54.016+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:30:54.016+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:30:54.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.693 seconds
[2025-03-18T16:31:24.249+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:31:24.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:31:24.251+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:31:24.250+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:31:25.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:31:25.961+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:31:25.961+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:31:25.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.744 seconds
[2025-03-18T16:31:56.269+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:31:56.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:31:56.271+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:31:56.271+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:31:58.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:31:58.149+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:31:58.149+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:31:58.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.907 seconds
[2025-03-18T16:32:28.344+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:32:28.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:32:28.346+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:32:28.346+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:32:30.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:32:30.356+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:32:30.355+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:32:30.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.039 seconds
[2025-03-18T16:33:00.509+0000] {processor.py:157} INFO - Started process (PID=105) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:33:00.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:33:00.510+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:33:00.510+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:33:03.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:33:03.037+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:33:03.037+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:33:03.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.559 seconds
[2025-03-18T16:33:33.238+0000] {processor.py:157} INFO - Started process (PID=107) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:33:33.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:33:33.239+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:33:33.239+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:33:35.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:33:35.156+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:33:35.156+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:33:35.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.953 seconds
[2025-03-18T16:34:05.379+0000] {processor.py:157} INFO - Started process (PID=109) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:34:05.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:34:05.381+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:34:05.381+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:34:06.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:34:06.852+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:34:06.851+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:34:06.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.503 seconds
[2025-03-18T16:34:37.215+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:34:37.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:34:37.217+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:34:37.216+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:34:39.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:34:39.629+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:34:39.629+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:34:39.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.443 seconds
[2025-03-18T16:35:09.859+0000] {processor.py:157} INFO - Started process (PID=113) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:35:09.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:35:09.860+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:35:09.860+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:35:11.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:35:11.089+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:35:11.089+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:35:11.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.259 seconds
[2025-03-18T16:35:41.276+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:35:41.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:35:41.278+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:35:41.278+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:35:42.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:35:42.969+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:35:42.969+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:35:42.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.724 seconds
[2025-03-18T16:36:13.181+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:36:13.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:36:13.183+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:36:13.182+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:36:14.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:36:14.425+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:36:14.424+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:36:14.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.273 seconds
[2025-03-18T16:36:44.627+0000] {processor.py:157} INFO - Started process (PID=119) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:36:44.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:36:44.628+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:36:44.628+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:36:46.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:36:46.314+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:36:46.313+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:36:46.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.714 seconds
[2025-03-18T16:37:16.519+0000] {processor.py:157} INFO - Started process (PID=121) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:37:16.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:37:16.521+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:37:16.521+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:37:17.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:37:17.848+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:37:17.848+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:37:17.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.356 seconds
[2025-03-18T16:37:48.061+0000] {processor.py:157} INFO - Started process (PID=123) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:37:48.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:37:48.062+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:37:48.062+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:37:49.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:37:49.484+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:37:49.483+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:37:49.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.454 seconds
[2025-03-18T16:38:19.728+0000] {processor.py:157} INFO - Started process (PID=125) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:38:19.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:38:19.730+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:38:19.730+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:38:20.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:38:20.835+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:38:20.835+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:38:20.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.139 seconds
[2025-03-18T16:38:51.036+0000] {processor.py:157} INFO - Started process (PID=136) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:38:51.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:38:51.038+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:38:51.038+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:38:51.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:38:51.963+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:38:51.963+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:38:51.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.954 seconds
[2025-03-18T16:39:22.154+0000] {processor.py:157} INFO - Started process (PID=138) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:39:22.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:39:22.156+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:39:22.155+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:39:23.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:39:23.026+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:39:23.026+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:39:23.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.905 seconds
[2025-03-18T16:39:53.300+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:39:53.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:39:53.302+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:39:53.302+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:39:54.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:39:54.792+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:39:54.792+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:39:54.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.522 seconds
[2025-03-18T16:40:24.983+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:40:24.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:40:24.984+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:40:24.984+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:40:26.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:40:26.260+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:40:26.260+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:40:26.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.309 seconds
[2025-03-18T16:40:56.480+0000] {processor.py:157} INFO - Started process (PID=183) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:40:56.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:40:56.482+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:40:56.482+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:40:57.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:40:57.889+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:40:57.888+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:40:57.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.437 seconds
[2025-03-18T16:41:28.070+0000] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:41:28.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:41:28.072+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:41:28.072+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:41:29.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:41:29.129+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:41:29.129+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:41:29.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.089 seconds
[2025-03-18T16:41:59.266+0000] {processor.py:157} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:41:59.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:41:59.267+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:41:59.267+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:42:00.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:42:00.706+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:42:00.706+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:42:00.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.466 seconds
[2025-03-18T16:42:30.921+0000] {processor.py:157} INFO - Started process (PID=207) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:42:30.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:42:30.923+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:42:30.922+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:42:31.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:42:31.873+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:42:31.873+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:42:31.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 0.981 seconds
[2025-03-18T16:43:02.089+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:43:02.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:43:02.091+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:43:02.090+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:43:03.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:43:03.545+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:43:03.545+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:43:03.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.486 seconds
[2025-03-18T16:43:33.758+0000] {processor.py:157} INFO - Started process (PID=246) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:43:33.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:43:33.759+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:43:33.759+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:43:35.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:43:35.755+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:43:35.754+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:43:35.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.028 seconds
[2025-03-18T16:44:05.957+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:44:05.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:44:05.959+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:44:05.959+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:44:07.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:44:07.526+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:44:07.526+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:44:07.535+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:44:07.534+0000] {dag.py:2963} INFO - Creating ORM DAG for etl_pipeline
[2025-03-18T16:44:07.543+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:44:07.542+0000] {dag.py:3722} INFO - Setting next_dagrun for etl_pipeline to 2025-03-18T15:00:00+00:00, run_after=2025-03-18T16:00:00+00:00
[2025-03-18T16:44:07.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.604 seconds
[2025-03-18T16:44:37.831+0000] {processor.py:157} INFO - Started process (PID=287) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:44:37.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:44:37.833+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:44:37.833+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:44:38.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:44:38.822+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:44:38.821+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:44:38.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.018 seconds
[2025-03-18T16:45:09.028+0000] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:45:09.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:45:09.030+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:45:09.029+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:45:11.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:45:11.358+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:45:11.358+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:45:11.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 2.356 seconds
[2025-03-18T16:45:41.557+0000] {processor.py:157} INFO - Started process (PID=315) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:45:41.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:45:41.559+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:45:41.559+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:45:42.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:45:42.684+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:45:42.684+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:45:42.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.160 seconds
[2025-03-18T16:46:12.752+0000] {processor.py:157} INFO - Started process (PID=317) to work on /opt/airflow/dags/etl_dags.py
[2025-03-18T16:46:12.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/etl_dags.py for tasks to queue
[2025-03-18T16:46:12.754+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:46:12.754+0000] {dagbag.py:536} INFO - Filling up the DagBag from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:46:14.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /opt/airflow/dags/etl_dags.py
[2025-03-18T16:46:14.127+0000] {logging_mixin.py:154} INFO - [2025-03-18T16:46:14.126+0000] {dag.py:2941} INFO - Sync 1 DAGs
[2025-03-18T16:46:14.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/etl_dags.py took 1.404 seconds
